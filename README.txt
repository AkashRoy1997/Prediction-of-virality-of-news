Problem statement: Crawl news and information websites & anticipate the likelihood of its virality

System: The whole code is written in google colab platform.

Training Dataset: The dataset used for model creation and training is dataset of Online news popularity collected from UCI depository.

Test Dataset: The dataset used for testing the model is generated by crawling the web page of world news of the news website of The Times of India.

Parameters used: The original dataset collected from UCI depository has many parameters. But generation of proper values of all the parameters for test data from web crawling of single page of single news paper of a single day is not possible.
		 Finding out the values of those parameters are beyond the scope this particular problem statement.
		 So, three important factors which can be found from test data are taken into consideration to show the flow of the algorithm and how one should approach this kind of problem.
		 Those three parameters are- 1. number of keywords 2. Sentiment score of title 3. Sentiment score of content
		 Those three factors along with social currency, celebrity factor etc. are in fact most important criteria of virality of news. Among them with given resources and scope of problem statement above mentioned three parameters are derivable.

Note: In our model, an article of news is viral when the number of shares crosses a fixed number of 1400. That means, whichever news is shared more than 1400 times is viral.
      And the viral news is labeled as '1' and the non-viral news is labeled as '0'. 