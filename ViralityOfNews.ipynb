{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ViralityOfNews.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    }
  },
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "dlsm7f4LpxPg",
        "colab_type": "text"
      },
      "source": [
        "**Model Creation and Training**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2O0wBqtJN1h6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import numpy as np\n",
        "import pandas as pd\n",
        "from time import time\n",
        "from IPython.display import display # Allows the use of display() for DataFrames\n",
        "%matplotlib inline"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "4kBkxeDyO9V7",
        "colab_type": "code",
        "colab": {
          "resources": {
            "http://localhost:8080/nbextensions/google.colab/files.js": {
              "data": "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",
              "ok": true,
              "headers": [
                [
                  "content-type",
                  "application/javascript"
                ]
              ],
              "status": 200,
              "status_text": ""
            }
          },
          "base_uri": "https://localhost:8080/",
          "height": 74
        },
        "outputId": "de43e559-2724-44f6-f983-a21cbbf157e2"
      },
      "source": [
        "from google.colab import files\n",
        "uploaded = files.upload()"
      ],
      "execution_count": 2,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "\n",
              "     <input type=\"file\" id=\"files-e7ac4f63-4f4d-4241-a11a-5c725e8d7a94\" name=\"files[]\" multiple disabled />\n",
              "     <output id=\"result-e7ac4f63-4f4d-4241-a11a-5c725e8d7a94\">\n",
              "      Upload widget is only available when the cell has been executed in the\n",
              "      current browser session. Please rerun this cell to enable.\n",
              "      </output>\n",
              "      <script src=\"/nbextensions/google.colab/files.js\"></script> "
            ],
            "text/plain": [
              "<IPython.core.display.HTML object>"
            ]
          },
          "metadata": {
            "tags": []
          }
        },
        {
          "output_type": "stream",
          "text": [
            "Saving OnlineNewsPopularity.csv to OnlineNewsPopularity.csv\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "DRrLHgiXPBrj",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 309
        },
        "outputId": "c93d7e1d-edde-40df-b72b-adc0e35edb0a"
      },
      "source": [
        "import io\n",
        "data = pd.read_csv(io.BytesIO(uploaded['OnlineNewsPopularity.csv']))\n",
        "display(data.head())"
      ],
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>url</th>\n",
              "      <th>timedelta</th>\n",
              "      <th>n_tokens_title</th>\n",
              "      <th>n_tokens_content</th>\n",
              "      <th>n_unique_tokens</th>\n",
              "      <th>n_non_stop_words</th>\n",
              "      <th>n_non_stop_unique_tokens</th>\n",
              "      <th>num_hrefs</th>\n",
              "      <th>num_self_hrefs</th>\n",
              "      <th>num_imgs</th>\n",
              "      <th>num_videos</th>\n",
              "      <th>average_token_length</th>\n",
              "      <th>num_keywords</th>\n",
              "      <th>data_channel_is_lifestyle</th>\n",
              "      <th>data_channel_is_entertainment</th>\n",
              "      <th>data_channel_is_bus</th>\n",
              "      <th>data_channel_is_socmed</th>\n",
              "      <th>data_channel_is_tech</th>\n",
              "      <th>data_channel_is_world</th>\n",
              "      <th>kw_min_min</th>\n",
              "      <th>kw_max_min</th>\n",
              "      <th>kw_avg_min</th>\n",
              "      <th>kw_min_max</th>\n",
              "      <th>kw_max_max</th>\n",
              "      <th>kw_avg_max</th>\n",
              "      <th>kw_min_avg</th>\n",
              "      <th>kw_max_avg</th>\n",
              "      <th>kw_avg_avg</th>\n",
              "      <th>self_reference_min_shares</th>\n",
              "      <th>self_reference_max_shares</th>\n",
              "      <th>self_reference_avg_sharess</th>\n",
              "      <th>weekday_is_monday</th>\n",
              "      <th>weekday_is_tuesday</th>\n",
              "      <th>weekday_is_wednesday</th>\n",
              "      <th>weekday_is_thursday</th>\n",
              "      <th>weekday_is_friday</th>\n",
              "      <th>weekday_is_saturday</th>\n",
              "      <th>weekday_is_sunday</th>\n",
              "      <th>is_weekend</th>\n",
              "      <th>LDA_00</th>\n",
              "      <th>LDA_01</th>\n",
              "      <th>LDA_02</th>\n",
              "      <th>LDA_03</th>\n",
              "      <th>LDA_04</th>\n",
              "      <th>global_subjectivity</th>\n",
              "      <th>global_sentiment_polarity</th>\n",
              "      <th>global_rate_positive_words</th>\n",
              "      <th>global_rate_negative_words</th>\n",
              "      <th>rate_positive_words</th>\n",
              "      <th>rate_negative_words</th>\n",
              "      <th>avg_positive_polarity</th>\n",
              "      <th>min_positive_polarity</th>\n",
              "      <th>max_positive_polarity</th>\n",
              "      <th>avg_negative_polarity</th>\n",
              "      <th>min_negative_polarity</th>\n",
              "      <th>max_negative_polarity</th>\n",
              "      <th>title_subjectivity</th>\n",
              "      <th>title_sentiment_polarity</th>\n",
              "      <th>abs_title_subjectivity</th>\n",
              "      <th>abs_title_sentiment_polarity</th>\n",
              "      <th>shares</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>http://mashable.com/2013/01/07/amazon-instant-...</td>\n",
              "      <td>731.0</td>\n",
              "      <td>12.0</td>\n",
              "      <td>219.0</td>\n",
              "      <td>0.663594</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.815385</td>\n",
              "      <td>4.0</td>\n",
              "      <td>2.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.680365</td>\n",
              "      <td>5.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>496.0</td>\n",
              "      <td>496.0</td>\n",
              "      <td>496.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.500331</td>\n",
              "      <td>0.378279</td>\n",
              "      <td>0.040005</td>\n",
              "      <td>0.041263</td>\n",
              "      <td>0.040123</td>\n",
              "      <td>0.521617</td>\n",
              "      <td>0.092562</td>\n",
              "      <td>0.045662</td>\n",
              "      <td>0.013699</td>\n",
              "      <td>0.769231</td>\n",
              "      <td>0.230769</td>\n",
              "      <td>0.378636</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>0.7</td>\n",
              "      <td>-0.350000</td>\n",
              "      <td>-0.600</td>\n",
              "      <td>-0.200000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>-0.187500</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.187500</td>\n",
              "      <td>593</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>http://mashable.com/2013/01/07/ap-samsung-spon...</td>\n",
              "      <td>731.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>255.0</td>\n",
              "      <td>0.604743</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.791946</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.913725</td>\n",
              "      <td>4.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.799756</td>\n",
              "      <td>0.050047</td>\n",
              "      <td>0.050096</td>\n",
              "      <td>0.050101</td>\n",
              "      <td>0.050001</td>\n",
              "      <td>0.341246</td>\n",
              "      <td>0.148948</td>\n",
              "      <td>0.043137</td>\n",
              "      <td>0.015686</td>\n",
              "      <td>0.733333</td>\n",
              "      <td>0.266667</td>\n",
              "      <td>0.286915</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>0.7</td>\n",
              "      <td>-0.118750</td>\n",
              "      <td>-0.125</td>\n",
              "      <td>-0.100000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>711</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>http://mashable.com/2013/01/07/apple-40-billio...</td>\n",
              "      <td>731.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>211.0</td>\n",
              "      <td>0.575130</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.663866</td>\n",
              "      <td>3.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.393365</td>\n",
              "      <td>6.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>918.0</td>\n",
              "      <td>918.0</td>\n",
              "      <td>918.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.217792</td>\n",
              "      <td>0.033334</td>\n",
              "      <td>0.033351</td>\n",
              "      <td>0.033334</td>\n",
              "      <td>0.682188</td>\n",
              "      <td>0.702222</td>\n",
              "      <td>0.323333</td>\n",
              "      <td>0.056872</td>\n",
              "      <td>0.009479</td>\n",
              "      <td>0.857143</td>\n",
              "      <td>0.142857</td>\n",
              "      <td>0.495833</td>\n",
              "      <td>0.100000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.466667</td>\n",
              "      <td>-0.800</td>\n",
              "      <td>-0.133333</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>http://mashable.com/2013/01/07/astronaut-notre...</td>\n",
              "      <td>731.0</td>\n",
              "      <td>9.0</td>\n",
              "      <td>531.0</td>\n",
              "      <td>0.503788</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.665635</td>\n",
              "      <td>9.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.404896</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.028573</td>\n",
              "      <td>0.419300</td>\n",
              "      <td>0.494651</td>\n",
              "      <td>0.028905</td>\n",
              "      <td>0.028572</td>\n",
              "      <td>0.429850</td>\n",
              "      <td>0.100705</td>\n",
              "      <td>0.041431</td>\n",
              "      <td>0.020716</td>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.385965</td>\n",
              "      <td>0.136364</td>\n",
              "      <td>0.8</td>\n",
              "      <td>-0.369697</td>\n",
              "      <td>-0.600</td>\n",
              "      <td>-0.166667</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>0.500000</td>\n",
              "      <td>0.000000</td>\n",
              "      <td>1200</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>http://mashable.com/2013/01/07/att-u-verse-apps/</td>\n",
              "      <td>731.0</td>\n",
              "      <td>13.0</td>\n",
              "      <td>1072.0</td>\n",
              "      <td>0.415646</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.540890</td>\n",
              "      <td>19.0</td>\n",
              "      <td>19.0</td>\n",
              "      <td>20.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>4.682836</td>\n",
              "      <td>7.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>545.0</td>\n",
              "      <td>16000.0</td>\n",
              "      <td>3151.157895</td>\n",
              "      <td>1.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.0</td>\n",
              "      <td>0.028633</td>\n",
              "      <td>0.028794</td>\n",
              "      <td>0.028575</td>\n",
              "      <td>0.028572</td>\n",
              "      <td>0.885427</td>\n",
              "      <td>0.513502</td>\n",
              "      <td>0.281003</td>\n",
              "      <td>0.074627</td>\n",
              "      <td>0.012127</td>\n",
              "      <td>0.860215</td>\n",
              "      <td>0.139785</td>\n",
              "      <td>0.411127</td>\n",
              "      <td>0.033333</td>\n",
              "      <td>1.0</td>\n",
              "      <td>-0.220192</td>\n",
              "      <td>-0.500</td>\n",
              "      <td>-0.050000</td>\n",
              "      <td>0.454545</td>\n",
              "      <td>0.136364</td>\n",
              "      <td>0.045455</td>\n",
              "      <td>0.136364</td>\n",
              "      <td>505</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                                 url  ...   shares\n",
              "0  http://mashable.com/2013/01/07/amazon-instant-...  ...      593\n",
              "1  http://mashable.com/2013/01/07/ap-samsung-spon...  ...      711\n",
              "2  http://mashable.com/2013/01/07/apple-40-billio...  ...     1500\n",
              "3  http://mashable.com/2013/01/07/astronaut-notre...  ...     1200\n",
              "4   http://mashable.com/2013/01/07/att-u-verse-apps/  ...      505\n",
              "\n",
              "[5 rows x 61 columns]"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "WJv9IkcUPMv5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Get the statistics of original target attribute\n",
        "popularity_raw = data[data.keys()[-1]]\n",
        "popularity_raw.describe()\n",
        "# Encode the label by threshold 1400\n",
        "from sklearn import preprocessing\n",
        "label_encoder = preprocessing.LabelEncoder()\n",
        "popular_label = pd.Series(label_encoder.fit_transform(popularity_raw>=1400))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LSApla3LPh3X",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "b2c84bdd-875d-4ffd-f083-95f08200f919"
      },
      "source": [
        "# Get the features from dataset\n",
        "data.drop(data.iloc[:, 46:59], inplace=True, axis=1)\n",
        "data.drop(data.iloc[:, 13:45], inplace=True, axis=1)\n",
        "data.drop(data.iloc[:, 0:12], inplace=True, axis=1)\n",
        "features_raw = data.drop([data.keys()[-1]], axis=1)\n",
        "display(features_raw.head())"
      ],
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_keywords</th>\n",
              "      <th>global_sentiment_polarity</th>\n",
              "      <th>abs_title_sentiment_polarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>5.0</td>\n",
              "      <td>0.092562</td>\n",
              "      <td>0.187500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>4.0</td>\n",
              "      <td>0.148948</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>6.0</td>\n",
              "      <td>0.323333</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>7.0</td>\n",
              "      <td>0.100705</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>7.0</td>\n",
              "      <td>0.281003</td>\n",
              "      <td>0.136364</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    num_keywords   global_sentiment_polarity   abs_title_sentiment_polarity\n",
              "0            5.0                    0.092562                       0.187500\n",
              "1            4.0                    0.148948                       0.000000\n",
              "2            6.0                    0.323333                       0.000000\n",
              "3            7.0                    0.100705                       0.000000\n",
              "4            7.0                    0.281003                       0.136364"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "7BB9wC9xvgiQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "4e998b04-964a-45d1-9265-fce6577439dd"
      },
      "source": [
        "# Normalize the numerical features\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "numerical = [' num_keywords',' global_sentiment_polarity',' abs_title_sentiment_polarity']\n",
        "features_raw[numerical] = scaler.fit_transform(data[numerical])\n",
        "display(features_raw.head(n = 1))"
      ],
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_keywords</th>\n",
              "      <th>global_sentiment_polarity</th>\n",
              "      <th>abs_title_sentiment_polarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.433591</td>\n",
              "      <td>0.1875</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    num_keywords   global_sentiment_polarity   abs_title_sentiment_polarity\n",
              "0       0.444444                    0.433591                         0.1875"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "srCnWjdeSlZk",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "c5225575-beef-48f5-9c5a-cd986a0df978"
      },
      "source": [
        "display(features_raw.head())"
      ],
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_keywords</th>\n",
              "      <th>global_sentiment_polarity</th>\n",
              "      <th>abs_title_sentiment_polarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.444444</td>\n",
              "      <td>0.433591</td>\n",
              "      <td>0.187500</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>0.333333</td>\n",
              "      <td>0.483864</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>0.555556</td>\n",
              "      <td>0.639345</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.440851</td>\n",
              "      <td>0.000000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>0.666667</td>\n",
              "      <td>0.601604</td>\n",
              "      <td>0.136364</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    num_keywords   global_sentiment_polarity   abs_title_sentiment_polarity\n",
              "0       0.444444                    0.433591                       0.187500\n",
              "1       0.333333                    0.483864                       0.000000\n",
              "2       0.555556                    0.639345                       0.000000\n",
              "3       0.666667                    0.440851                       0.000000\n",
              "4       0.666667                    0.601604                       0.136364"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "6qpBzk26WNdQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 34
        },
        "outputId": "d28e29a6-38de-4862-9119-71fdc554469f"
      },
      "source": [
        "from sklearn.feature_selection import RFECV\n",
        "from sklearn.svm import SVR\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "\n",
        "estimator = AdaBoostClassifier(random_state=0)\n",
        "selector = RFECV(estimator, step=1, cv=5)\n",
        "selector = selector.fit(features_raw, popular_label)\n",
        "selector.ranking_\n",
        "\n",
        "estimator_LR = LogisticRegression(random_state=0)\n",
        "selector_LR = RFECV(estimator_LR, step=1, cv=5)\n",
        "selector_LR = selector_LR.fit(features_raw, popular_label)\n",
        "selector_LR.ranking_\n",
        "\n",
        "estimator_RF = RandomForestClassifier(random_state=0)\n",
        "selector_RF = RFECV(estimator_RF, step=1, cv=5)\n",
        "selector_RF = selector_RF.fit(features_raw, popular_label)\n",
        "selector_RF.ranking_"
      ],
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 41
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "z42p539iXG8N",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "7c8e1717-916a-42e9-8243-b7c4e404be26"
      },
      "source": [
        "# Split data into training and testing sets\n",
        "from sklearn.metrics import accuracy_score, fbeta_score, roc_curve, auc, roc_auc_score\n",
        "from sklearn.model_selection import train_test_split\n",
        "\n",
        "features_ADA = features_raw[features_raw.columns.values[selector.ranking_==1]]\n",
        "features_LR = features_raw[features_raw.columns.values[selector_LR.ranking_==1]]\n",
        "features_RF = features_raw[features_raw.columns.values[selector_RF.ranking_==1]]\n",
        "\n",
        "\n",
        "X_train_ADA, X_test_ADA, y_train_ADA, y_test_ADA = train_test_split(features_ADA, popular_label, test_size = 0.1, random_state = 0)\n",
        "\n",
        "X_train_LR, X_test_LR, y_train_LR, y_test_LR = train_test_split(features_LR, popular_label, test_size = 0.1, random_state = 0)\n",
        "\n",
        "X_train_RF, X_test_RF, y_train_RF, y_test_RF = train_test_split(features_RF, popular_label, test_size = 0.1, random_state = 0)\n",
        "\n",
        "print (\"Training set has {} samples.\".format(X_train_ADA.shape[0]))\n",
        "print (\"Testing set has {} samples.\".format(X_test_ADA.shape[0]))"
      ],
      "execution_count": 42,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Training set has 35679 samples.\n",
            "Testing set has 3965 samples.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "cWxpHIUEYVjc",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def train_predict(learner, sample_size, X_train, y_train, X_test, y_test): \n",
        "    '''\n",
        "    inputs:\n",
        "       - learner: the learning algorithm to be trained and predicted on\n",
        "       - sample_size: the size of samples (number) to be drawn from training set\n",
        "       - X_train: features training set\n",
        "       - y_train: income training set\n",
        "       - X_test: features testing set\n",
        "       - y_test: income testing set\n",
        "    '''\n",
        "    \n",
        "    results = {}\n",
        "    \n",
        "    start = time() # Get start time\n",
        "    learner.fit(X_train[:sample_size], y_train[:sample_size])\n",
        "    end = time() # Get end time\n",
        "\n",
        "    results['train_time'] = end-start\n",
        "        \n",
        "    # Get predictions on the first 4000 training samples\n",
        "    start = time() # Get start time\n",
        "    predictions_test = learner.predict(X_test)\n",
        "    predictions_train = learner.predict(X_train[:4000])\n",
        "    end = time() # Get end time\n",
        "    \n",
        "    # Calculate the total prediction time\n",
        "    results['pred_time'] = end-start\n",
        "            \n",
        "    # Compute accuracy on the first 4000 training samples\n",
        "    results['acc_train'] = accuracy_score(y_train[:4000],predictions_train)\n",
        "        \n",
        "    # Compute accuracy on test set\n",
        "    results['acc_test'] = accuracy_score(y_test,predictions_test)\n",
        "    \n",
        "    # Compute F-score on the the first 4000 training samples\n",
        "    results['f_train'] = fbeta_score(y_train[:4000],predictions_train,beta=1)\n",
        "        \n",
        "    # Compute F-score on the test set\n",
        "    results['f_test'] = fbeta_score(y_test,predictions_test,beta=1)\n",
        "    \n",
        "    # Compute AUC on the the first 4000 training samples\n",
        "    results['auc_train'] = roc_auc_score(y_train[:4000],predictions_train)\n",
        "        \n",
        "    # Compute AUC on the test set\n",
        "    results['auc_test'] = roc_auc_score(y_test,predictions_test)\n",
        "       \n",
        "    # Success\n",
        "    print (\"{} trained on {} samples.\".format(learner.__class__.__name__, sample_size))\n",
        "    print (\"{} with accuracy {}, F1 {} and AUC {}.\".format(learner.__class__.__name__,\\\n",
        "          results['acc_test'],results['f_test'], results['auc_test']))   \n",
        "    # Return the results\n",
        "    return results"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "CXFzb3W_ZdxQ",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "757fe115-8f9d-4602-d2b8-2679671027dc"
      },
      "source": [
        "# Import the three supervised learning models from sklearn\n",
        "from sklearn.naive_bayes import GaussianNB\n",
        "from sklearn.linear_model import LogisticRegression\n",
        "from sklearn.ensemble import RandomForestClassifier\n",
        "from sklearn.ensemble import AdaBoostClassifier\n",
        "from sklearn.svm import SVC\n",
        "from sklearn.tree import DecisionTreeClassifier\n",
        "from sklearn.neighbors import KNeighborsClassifier\n",
        "from sklearn.ensemble import BaggingClassifier\n",
        "from sklearn.linear_model import SGDClassifier\n",
        "# Initialize the three models\n",
        "clf_A = AdaBoostClassifier(random_state=0)\n",
        "clf_B = LogisticRegression(random_state=0,C=1.0)\n",
        "clf_C = RandomForestClassifier(random_state=0)\n",
        "\n",
        "# Calculate the number of samples for 1%, 10%, and 100% of the training data\n",
        "samples_1 = int(X_train_ADA.shape[0]*0.01)\n",
        "samples_10 = int(X_train_ADA.shape[0]*0.1)\n",
        "samples_100 = X_train_ADA.shape[0]\n",
        "\n",
        "# Collect results on the learners\n",
        "results = {}\n",
        "for clf in [clf_A, clf_B, clf_C]:\n",
        "    clf_name = clf.__class__.__name__\n",
        "    results[clf_name] = {}\n",
        "    for i, samples in enumerate([samples_1, samples_10, samples_100]):\n",
        "        if clf == clf_A:\n",
        "            results[clf_name][i] = \\\n",
        "            train_predict(clf, samples, X_train_ADA, y_train_ADA, X_test_ADA, y_test_ADA)\n",
        "        elif clf == clf_B:\n",
        "            results[clf_name][i] = \\\n",
        "            train_predict(clf, samples, X_train_LR, y_train_LR, X_test_LR, y_test_LR)\n",
        "        else:\n",
        "            results[clf_name][i] = \\\n",
        "            train_predict(clf, samples, X_train_RF, y_train_RF, X_test_RF, y_test_RF)\n"
      ],
      "execution_count": 44,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AdaBoostClassifier trained on 356 samples.\n",
            "AdaBoostClassifier with accuracy 0.5397225725094578, F1 0.6102925475122785 and AUC 0.531909675154826.\n",
            "AdaBoostClassifier trained on 3567 samples.\n",
            "AdaBoostClassifier with accuracy 0.5440100882723834, F1 0.6153191489361702 and AUC 0.5359903280592908.\n",
            "AdaBoostClassifier trained on 35679 samples.\n",
            "AdaBoostClassifier with accuracy 0.5586380832282472, F1 0.6430028559771521 and AUC 0.5480667342481491.\n",
            "LogisticRegression trained on 356 samples.\n",
            "LogisticRegression with accuracy 0.5250945775535939, F1 0.6885028949545079 and AUC 0.49978559800173766.\n",
            "LogisticRegression trained on 3567 samples.\n",
            "LogisticRegression with accuracy 0.5533417402269861, F1 0.6488201467380528 and AUC 0.5409493786806101.\n",
            "LogisticRegression trained on 35679 samples.\n",
            "LogisticRegression with accuracy 0.5523329129886507, F1 0.649417341497136 and AUC 0.5396815881614384.\n",
            "RandomForestClassifier trained on 356 samples.\n",
            "RandomForestClassifier with accuracy 0.519546027742749, F1 0.5539686256146101 and AUC 0.5169622463717467.\n",
            "RandomForestClassifier trained on 3567 samples.\n",
            "RandomForestClassifier with accuracy 0.5097099621689786, F1 0.5382422802850355 and AUC 0.5078827490188015.\n",
            "RandomForestClassifier trained on 35679 samples.\n",
            "RandomForestClassifier with accuracy 0.5129886506935687, F1 0.5427421264503907 and AUC 0.5110032482986864.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VzBSuBPzZ4iT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def gridsearch(clf,parameters,X_train, y_train, X_test, y_test):\n",
        "    scorer = make_scorer(roc_auc_score)\n",
        "    grid_obj = GridSearchCV(clf, parameters, scoring=scorer)\n",
        "\n",
        "# Fit the grid search object to the training data and find the optimal parameters\n",
        "    grid_fit = grid_obj.fit(X_train, y_train)\n",
        "\n",
        "# Get the estimator\n",
        "    best_clf = grid_fit.best_estimator_\n",
        "\n",
        "# Make predictions using the unoptimized and model\n",
        "    predictions = (clf.fit(X_train, y_train)).predict(X_test)\n",
        "    best_predictions = best_clf.predict(X_test)\n",
        "\n",
        "# Report the before-and-afterscores\n",
        "    print (clf.__class__.__name__)\n",
        "    print (\"Unoptimized model\\n------\")\n",
        "    print (\"Accuracy score on testing data: {:.4f}\".format(accuracy_score(y_test, predictions)))\n",
        "    print (\"F-score on testing data: {:.4f}\".format(fbeta_score(y_test, predictions,beta=1)))\n",
        "    print (\"AUC on testing data: {:.4f}\".format(roc_auc_score(y_test, predictions)))\n",
        "    print (\"\\nOptimized Model\\n------\")\n",
        "    print (\"Final accuracy score on the testing data: {:.4f}\".format(accuracy_score(y_test, best_predictions)))\n",
        "    print (\"Final F-score on the testing data: {:.4f}\".format(fbeta_score(y_test, best_predictions, beta=1)))\n",
        "    print (\"Final AUC on the testing data: {:.4f}\".format(roc_auc_score(y_test, best_predictions)))\n",
        "\n",
        "    print (best_clf)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BwcMaRhhadKT",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "# Do the grid search for hyperparameters\n",
        "from sklearn.metrics import make_scorer \n",
        "from sklearn.model_selection import GridSearchCV\n",
        "parameters_RF = {\"n_estimators\": [10,20,50,100,250,500]}\n",
        "parameters_LR = {\"penalty\": ['l1','l2'],\n",
        "              \"C\": [0.1,0.5,1.,2.,2.5,5]}\n",
        "parameters_ADA = {\"n_estimators\": [100,200,300,400],\n",
        "              \"learning_rate\": [0.1,0.5,1]}"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qKb6Q3SaajXo",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 255
        },
        "outputId": "24605260-0854-428d-daf8-7fb3b125d0d1"
      },
      "source": [
        "# Grid search for Adaboost\n",
        "gridsearch(clf_A,parameters_ADA,X_train_ADA, y_train_ADA, X_test_ADA, y_test_ADA)"
      ],
      "execution_count": 47,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AdaBoostClassifier\n",
            "Unoptimized model\n",
            "------\n",
            "Accuracy score on testing data: 0.5586\n",
            "F-score on testing data: 0.6430\n",
            "AUC on testing data: 0.5481\n",
            "\n",
            "Optimized Model\n",
            "------\n",
            "Final accuracy score on the testing data: 0.5596\n",
            "Final F-score on the testing data: 0.6434\n",
            "Final AUC on the testing data: 0.5492\n",
            "AdaBoostClassifier(algorithm='SAMME.R', base_estimator=None, learning_rate=1,\n",
            "                   n_estimators=400, random_state=0)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qOJPC74Ba67A",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 734
        },
        "outputId": "d8b56c72-659d-4762-ebd4-1fb01cb5bab0"
      },
      "source": [
        "# Grid search for logistic regression\n",
        "gridsearch(clf_B,parameters_LR,X_train_LR, y_train_LR, X_test_LR, y_test_LR)"
      ],
      "execution_count": 48,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n",
            "/usr/local/lib/python3.6/dist-packages/sklearn/model_selection/_validation.py:536: FitFailedWarning: Estimator fit failed. The score on this train-test partition for these parameters will be set to nan. Details: \n",
            "ValueError: Solver lbfgs supports only 'l2' or 'none' penalties, got l1 penalty.\n",
            "\n",
            "  FitFailedWarning)\n"
          ],
          "name": "stderr"
        },
        {
          "output_type": "stream",
          "text": [
            "LogisticRegression\n",
            "Unoptimized model\n",
            "------\n",
            "Accuracy score on testing data: 0.5523\n",
            "F-score on testing data: 0.6494\n",
            "AUC on testing data: 0.5397\n",
            "\n",
            "Optimized Model\n",
            "------\n",
            "Final accuracy score on the testing data: 0.5518\n",
            "Final F-score on the testing data: 0.6487\n",
            "Final AUC on the testing data: 0.5392\n",
            "LogisticRegression(C=2.0, class_weight=None, dual=False, fit_intercept=True,\n",
            "                   intercept_scaling=1, l1_ratio=None, max_iter=100,\n",
            "                   multi_class='auto', n_jobs=None, penalty='l2',\n",
            "                   random_state=0, solver='lbfgs', tol=0.0001, verbose=0,\n",
            "                   warm_start=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "dq0_Qv9PbpC7",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 357
        },
        "outputId": "674ffb66-e1c5-4aea-a0fa-809108f52b8d"
      },
      "source": [
        "# Grid search for RF\n",
        "gridsearch(clf_C,parameters_RF,X_train_RF, y_train_RF, X_test_RF, y_test_RF)"
      ],
      "execution_count": 49,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "RandomForestClassifier\n",
            "Unoptimized model\n",
            "------\n",
            "Accuracy score on testing data: 0.5130\n",
            "F-score on testing data: 0.5427\n",
            "AUC on testing data: 0.5110\n",
            "\n",
            "Optimized Model\n",
            "------\n",
            "Final accuracy score on the testing data: 0.5148\n",
            "Final F-score on the testing data: 0.5423\n",
            "Final AUC on the testing data: 0.5130\n",
            "RandomForestClassifier(bootstrap=True, ccp_alpha=0.0, class_weight=None,\n",
            "                       criterion='gini', max_depth=None, max_features='auto',\n",
            "                       max_leaf_nodes=None, max_samples=None,\n",
            "                       min_impurity_decrease=0.0, min_impurity_split=None,\n",
            "                       min_samples_leaf=1, min_samples_split=2,\n",
            "                       min_weight_fraction_leaf=0.0, n_estimators=20,\n",
            "                       n_jobs=None, oob_score=False, random_state=0, verbose=0,\n",
            "                       warm_start=False)\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "qHX4MrJzbzYe",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 323
        },
        "outputId": "a0c98267-67f4-4838-fc92-05cdfdcc25c9"
      },
      "source": [
        "# Run the classifier with refined hyperparameters\n",
        "clf_A = AdaBoostClassifier(random_state=0,learning_rate=1,n_estimators=400)\n",
        "clf_B = LogisticRegression(random_state=0, C=2.0)\n",
        "clf_C = RandomForestClassifier(random_state=0, n_estimators=20)\n",
        "\n",
        "# Collect results on the learners\n",
        "results = {}\n",
        "for clf in [clf_A, clf_B, clf_C]:\n",
        "    clf_name = clf.__class__.__name__\n",
        "    results[clf_name] = {}\n",
        "    for i, samples in enumerate([samples_1, samples_10, samples_100]):\n",
        "        if clf == clf_A:\n",
        "            results[clf_name][i] = \\\n",
        "            train_predict(clf, samples, X_train_ADA, y_train_ADA, X_test_ADA, y_test_ADA)\n",
        "        elif clf == clf_B:\n",
        "            results[clf_name][i] = \\\n",
        "            train_predict(clf, samples, X_train_LR, y_train_LR, X_test_LR, y_test_LR)\n",
        "        else:\n",
        "            results[clf_name][i] = \\\n",
        "            train_predict(clf, samples, X_train_RF, y_train_RF, X_test_RF, y_test_RF)"
      ],
      "execution_count": 50,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "AdaBoostClassifier trained on 356 samples.\n",
            "AdaBoostClassifier with accuracy 0.5273644388398486, F1 0.5619448340345957 and AUC 0.524711073856833.\n",
            "AdaBoostClassifier trained on 3567 samples.\n",
            "AdaBoostClassifier with accuracy 0.5435056746532156, F1 0.6014971378247469 and AUC 0.5375098910618472.\n",
            "AdaBoostClassifier trained on 35679 samples.\n",
            "AdaBoostClassifier with accuracy 0.5596469104665825, F1 0.6433823529411765 and AUC 0.5491550699121424.\n",
            "LogisticRegression trained on 356 samples.\n",
            "LogisticRegression with accuracy 0.5263556116015132, F1 0.6885572139303482 and AUC 0.5012421541112891.\n",
            "LogisticRegression trained on 3567 samples.\n",
            "LogisticRegression with accuracy 0.5525851197982345, F1 0.6452 and AUC 0.5407419916198282.\n",
            "LogisticRegression trained on 35679 samples.\n",
            "LogisticRegression with accuracy 0.551828499369483, F1 0.6487448112275154 and AUC 0.5392271477570312.\n",
            "RandomForestClassifier trained on 356 samples.\n",
            "RandomForestClassifier with accuracy 0.5253467843631778, F1 0.5475961538461538 and AUC 0.5242007690412187.\n",
            "RandomForestClassifier trained on 3567 samples.\n",
            "RandomForestClassifier with accuracy 0.5051702395964691, F1 0.5267727930535456 and AUC 0.5041516950894928.\n",
            "RandomForestClassifier trained on 35679 samples.\n",
            "RandomForestClassifier with accuracy 0.5147540983606558, F1 0.5423406279733587 and AUC 0.5130167904441757.\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "qKGIbppcqDdg",
        "colab_type": "text"
      },
      "source": [
        "**Crawling news and dataset generation**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UinJlGs94tzA",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 870
        },
        "outputId": "41cf1f1b-0b45-4cd4-f38c-5031dde37e30"
      },
      "source": [
        "pip install newspaper3k"
      ],
      "execution_count": 53,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting newspaper3k\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/d7/b9/51afecb35bb61b188a4b44868001de348a0e8134b4dfa00ffc191567c4b9/newspaper3k-0.2.8-py3-none-any.whl (211kB)\n",
            "\u001b[K     || 215kB 2.6MB/s \n",
            "\u001b[?25hCollecting feedparser>=5.2.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/91/d8/7d37fec71ff7c9dbcdd80d2b48bcdd86d6af502156fc93846fb0102cb2c4/feedparser-5.2.1.tar.bz2 (192kB)\n",
            "\u001b[K     || 194kB 48.5MB/s \n",
            "\u001b[?25hCollecting jieba3k>=0.35.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/a9/cb/2c8332bcdc14d33b0bedd18ae0a4981a069c3513e445120da3c3f23a8aaa/jieba3k-0.35.1.zip (7.4MB)\n",
            "\u001b[K     || 7.4MB 43.4MB/s \n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.5.3 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (2.8.1)\n",
            "Requirement already satisfied: Pillow>=3.3.0 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (7.0.0)\n",
            "Requirement already satisfied: PyYAML>=3.11 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (3.13)\n",
            "Requirement already satisfied: requests>=2.10.0 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (2.21.0)\n",
            "Collecting tinysegmenter==0.3\n",
            "  Downloading https://files.pythonhosted.org/packages/17/82/86982e4b6d16e4febc79c2a1d68ee3b707e8a020c5d2bc4af8052d0f136a/tinysegmenter-0.3.tar.gz\n",
            "Requirement already satisfied: nltk>=3.2.1 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (3.2.5)\n",
            "Collecting cssselect>=0.9.2\n",
            "  Downloading https://files.pythonhosted.org/packages/3b/d4/3b5c17f00cce85b9a1e6f91096e1cc8e8ede2e1be8e96b87ce1ed09e92c5/cssselect-1.1.0-py2.py3-none-any.whl\n",
            "Collecting tldextract>=2.0.1\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/fd/0e/9ab599d6e78f0340bb1d1e28ddeacb38c8bb7f91a1b0eae9a24e9603782f/tldextract-2.2.2-py2.py3-none-any.whl (48kB)\n",
            "\u001b[K     || 51kB 7.2MB/s \n",
            "\u001b[?25hRequirement already satisfied: beautifulsoup4>=4.4.1 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (4.6.3)\n",
            "Requirement already satisfied: lxml>=3.6.0 in /usr/local/lib/python3.6/dist-packages (from newspaper3k) (4.2.6)\n",
            "Collecting feedfinder2>=0.0.4\n",
            "  Downloading https://files.pythonhosted.org/packages/35/82/1251fefec3bb4b03fd966c7e7f7a41c9fc2bb00d823a34c13f847fd61406/feedfinder2-0.0.4.tar.gz\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.6/dist-packages (from python-dateutil>=2.5.3->newspaper3k) (1.12.0)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.6/dist-packages (from requests>=2.10.0->newspaper3k) (2020.4.5.1)\n",
            "Requirement already satisfied: idna<2.9,>=2.5 in /usr/local/lib/python3.6/dist-packages (from requests>=2.10.0->newspaper3k) (2.8)\n",
            "Requirement already satisfied: chardet<3.1.0,>=3.0.2 in /usr/local/lib/python3.6/dist-packages (from requests>=2.10.0->newspaper3k) (3.0.4)\n",
            "Requirement already satisfied: urllib3<1.25,>=1.21.1 in /usr/local/lib/python3.6/dist-packages (from requests>=2.10.0->newspaper3k) (1.24.3)\n",
            "Requirement already satisfied: setuptools in /usr/local/lib/python3.6/dist-packages (from tldextract>=2.0.1->newspaper3k) (46.1.3)\n",
            "Collecting requests-file>=1.4\n",
            "  Downloading https://files.pythonhosted.org/packages/77/86/cdb5e8eaed90796aa83a6d9f75cfbd37af553c47a291cd47bc410ef9bdb2/requests_file-1.5.1-py2.py3-none-any.whl\n",
            "Building wheels for collected packages: feedparser, jieba3k, tinysegmenter, feedfinder2\n",
            "  Building wheel for feedparser (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for feedparser: filename=feedparser-5.2.1-cp36-none-any.whl size=44940 sha256=3e465d280ec736a10125ae03e904f945fc94908391c7bddc4a67eeeb01fddf93\n",
            "  Stored in directory: /root/.cache/pip/wheels/8c/69/b7/f52763c41c5471df57703a0ef718a32a5e81ee35dcf6d4f97f\n",
            "  Building wheel for jieba3k (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for jieba3k: filename=jieba3k-0.35.1-cp36-none-any.whl size=7398406 sha256=5dc09e5865cbbf12a4c1bf823460ccbe0ca834485c8b936f086139b7d0e5fca6\n",
            "  Stored in directory: /root/.cache/pip/wheels/83/15/9c/a3f1f67e7f7181170ad37d32e503c35da20627c013f438ed34\n",
            "  Building wheel for tinysegmenter (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for tinysegmenter: filename=tinysegmenter-0.3-cp36-none-any.whl size=13539 sha256=b6747238a8c8314d9267e128b6b1744d6bd36e8dcdc7a458539c3938bafa8654\n",
            "  Stored in directory: /root/.cache/pip/wheels/81/2b/43/a02ede72324dd40cdd7ca53aad718c7710628e91b8b0dc0f02\n",
            "  Building wheel for feedfinder2 (setup.py) ... \u001b[?25l\u001b[?25hdone\n",
            "  Created wheel for feedfinder2: filename=feedfinder2-0.0.4-cp36-none-any.whl size=3357 sha256=5458575683fc871e515a5f2277d9198e45c9b339396804715f4b05fdfb19fe38\n",
            "  Stored in directory: /root/.cache/pip/wheels/de/03/ca/778e3a7a627e3d98836cc890e7cb40c7575424cfd3340f40ed\n",
            "Successfully built feedparser jieba3k tinysegmenter feedfinder2\n",
            "Installing collected packages: feedparser, jieba3k, tinysegmenter, cssselect, requests-file, tldextract, feedfinder2, newspaper3k\n",
            "Successfully installed cssselect-1.1.0 feedfinder2-0.0.4 feedparser-5.2.1 jieba3k-0.35.1 newspaper3k-0.2.8 requests-file-1.5.1 tinysegmenter-0.3 tldextract-2.2.2\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "9PbvQvQpcTAE",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import requests\n",
        "from bs4 import BeautifulSoup\n",
        "from newspaper import Article  \n",
        "import csv \n",
        "import pandas as pd\n",
        "import numpy as np\n"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nfgmvhN243Ze",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 68
        },
        "outputId": "d462da59-1b88-400b-97ec-bffe157e0aa6"
      },
      "source": [
        "import nltk\n",
        "nltk.download('punkt')"
      ],
      "execution_count": 55,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "[nltk_data] Downloading package punkt to /root/nltk_data...\n",
            "[nltk_data]   Unzipping tokenizers/punkt.zip.\n"
          ],
          "name": "stdout"
        },
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "True"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 55
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "krnsDGcQqafm",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "url = \"https://timesofindia.indiatimes.com/world\"\n",
        "r = requests.get(url)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "mqwkgFiwqgsz",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "soup = BeautifulSoup(r.content, 'html5lib') \n",
        "table = soup.findAll('a', attrs = {'class':'w_img'})"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "3EFvi_dLqhk5",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "news=[]\n",
        "for row in table: \n",
        "    if not row['href'].startswith('http'):\n",
        "        news.append('https://timesofindia.indiatimes.com'+row['href'])"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2qIlCXuNqlIi",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "df=[]\n",
        "for i in news:\n",
        "    article = Article(i, language=\"en\")\n",
        "    article.download() \n",
        "    article.parse() \n",
        "    article.nlp() \n",
        "    data={}\n",
        "    data['Title']=article.title\n",
        "    data['Text']=article.text\n",
        "    data['Summary']=article.summary\n",
        "    data['Keywords']=article.keywords\n",
        "    df.append(data)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "vtH9uAl3qo01",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 289
        },
        "outputId": "a455e1e6-599a-47ef-f35a-ea1980f82420"
      },
      "source": [
        "dataset=pd.DataFrame(df)\n",
        "dataset.head()"
      ],
      "execution_count": 60,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>Title</th>\n",
              "      <th>Text</th>\n",
              "      <th>Summary</th>\n",
              "      <th>Keywords</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>France Lockdown Lift: France to outline plans ...</td>\n",
              "      <td>Nurse Sandrine poses as she works in a hotel o...</td>\n",
              "      <td>Restaurants, cafes and cinemas will have to re...</td>\n",
              "      <td>[outline, week, lift, lawmakers, times, plans,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>Covid-19: Testing won't 'be a problem' for reo...</td>\n",
              "      <td>Apr 28, 2020, 08:40AM IST\\n\\nSource: AP\\n\\nThe...</td>\n",
              "      <td>Apr 28, 2020, 08:40AM ISTSource: APThe White H...</td>\n",
              "      <td>[trump, problem, virus, unveiling, house, bett...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>Covid-19: Some Georgia restaurants reopen for ...</td>\n",
              "      <td>Apr 28, 2020, 08:43AM IST\\n\\nSource: AP\\n\\nWit...</td>\n",
              "      <td>Apr 28, 2020, 08:43AM ISTSource: APWith tables...</td>\n",
              "      <td>[wearing, dinein, customers, service, allowed,...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>'Very good idea' on Kim Jong Un's health: Pres...</td>\n",
              "      <td>Apr 28, 2020, 08:39AM IST\\n\\nSource: AP\\n\\nNor...</td>\n",
              "      <td>Apr 28, 2020, 08:39AM ISTSource: APNorth Korea...</td>\n",
              "      <td>[health, trump, idea, reporters, korean, rumor...</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>Covid-19: Mayor entertains residents after imp...</td>\n",
              "      <td>Apr 27, 2020, 08:27AM IST\\n\\nSource: AP\\n\\nThe...</td>\n",
              "      <td>Apr 27, 2020, 08:27AM ISTSource: APThe videos,...</td>\n",
              "      <td>[tshirt, residents, facebook, try, way, imposi...</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "                                               Title  ...                                           Keywords\n",
              "0  France Lockdown Lift: France to outline plans ...  ...  [outline, week, lift, lawmakers, times, plans,...\n",
              "1  Covid-19: Testing won't 'be a problem' for reo...  ...  [trump, problem, virus, unveiling, house, bett...\n",
              "2  Covid-19: Some Georgia restaurants reopen for ...  ...  [wearing, dinein, customers, service, allowed,...\n",
              "3  'Very good idea' on Kim Jong Un's health: Pres...  ...  [health, trump, idea, reporters, korean, rumor...\n",
              "4  Covid-19: Mayor entertains residents after imp...  ...  [tshirt, residents, facebook, try, way, imposi...\n",
              "\n",
              "[5 rows x 4 columns]"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 60
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "BGyItk-Sqr4G",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "import time\n",
        "import math\n",
        "import re\n",
        "from textblob import TextBlob\n",
        "import pandas as pd\n",
        "\n",
        "import nltk as nltk\n",
        "from nltk.corpus import stopwords\n",
        "from nltk.stem.wordnet import WordNetLemmatizer\n",
        "\n",
        "import string\n",
        "\n",
        "import warnings\n",
        "warnings.filterwarnings(action='ignore', category=UserWarning, module='gensim')\n",
        "\n",
        "import gensim\n",
        "from gensim import corpora, models\n",
        "from gensim.models.ldamulticore import LdaMulticore"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "VTIUlTEXrF5a",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset['Text_clean'] = dataset['Text'].map(lambda x: re.sub('[^a-zA-Z0-9  . , : - _]', '', str(x)))\n",
        "dataset['Title_clean'] = dataset['Title'].map(lambda x: re.sub('[^a-zA-Z0-9  . , : - _]', '', str(x)))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "UK3l-LICrM6t",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset.Text_clean = dataset.Text_clean.str.lower()\n",
        "dataset.Title_clean = dataset.Title_clean.str.lower()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "h3BvBGeK5GSd",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 122
        },
        "outputId": "3a5a047f-14f9-40cf-8482-f9494756a0b7"
      },
      "source": [
        "pip install vaderSentiment"
      ],
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "stream",
          "text": [
            "Collecting vaderSentiment\n",
            "\u001b[?25l  Downloading https://files.pythonhosted.org/packages/44/a3/1218a3b5651dbcba1699101c84e5c84c36cbba360d9dbf29f2ff18482982/vaderSentiment-3.3.1-py2.py3-none-any.whl (125kB)\n",
            "\r\u001b[K     |                             | 10kB 14.9MB/s eta 0:00:01\r\u001b[K     |                          | 20kB 1.6MB/s eta 0:00:01\r\u001b[K     |                        | 30kB 2.4MB/s eta 0:00:01\r\u001b[K     |                     | 40kB 3.1MB/s eta 0:00:01\r\u001b[K     |                   | 51kB 2.0MB/s eta 0:00:01\r\u001b[K     |                | 61kB 2.4MB/s eta 0:00:01\r\u001b[K     |             | 71kB 2.7MB/s eta 0:00:01\r\u001b[K     |           | 81kB 3.1MB/s eta 0:00:01\r\u001b[K     |        | 92kB 2.4MB/s eta 0:00:01\r\u001b[K     |      | 102kB 2.6MB/s eta 0:00:01\r\u001b[K     |   | 112kB 2.6MB/s eta 0:00:01\r\u001b[K     || 122kB 2.6MB/s eta 0:00:01\r\u001b[K     || 133kB 2.6MB/s \n",
            "\u001b[?25hInstalling collected packages: vaderSentiment\n",
            "Successfully installed vaderSentiment-3.3.1\n"
          ],
          "name": "stdout"
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "FPl19C4WrQS6",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "from vaderSentiment.vaderSentiment import SentimentIntensityAnalyzer\n",
        "analyser = SentimentIntensityAnalyzer()"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "Q3jfEexJrUun",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset['vader_sentiment_Text'] = dataset.Text_clean.apply(lambda x:analyser.polarity_scores(x))\n",
        "dataset['vader_sentiment_Title'] = dataset.Title_clean.apply(lambda x:analyser.polarity_scores(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "LFQf8cpzrZQO",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "def sentiment_parser(x):\n",
        "    if x['neg'] > 0:\n",
        "        return x['neg']\n",
        "    elif x['pos'] > 0:\n",
        "        return x['pos']\n",
        "    elif x['compound'] > 0:\n",
        "      return x['compound']\n",
        "    else:\n",
        "      return 0"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "ZMXSGcJ3rcaN",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset['v_sentiment_Text'] = dataset['vader_sentiment_Text'].apply(lambda x:sentiment_parser(x))\n",
        "dataset['v_sentiment_Title'] = dataset['vader_sentiment_Title'].apply(lambda x:sentiment_parser(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "rHikb87srgH3",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset.drop(dataset.iloc[:, 4:8], inplace=True, axis=1)\n",
        "dataset.drop(dataset.iloc[:, 0:3], inplace=True, axis=1)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "MEgYBEt_roqj",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "dataset['num_keywords'] = dataset['Keywords'].apply(lambda x: len(x))"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "2Xjq0wdD1O-_",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 204
        },
        "outputId": "df620118-2f6d-4865-9bf2-00f65a3526ae"
      },
      "source": [
        "dataset[' num_keywords'] = dataset['num_keywords']\n",
        "dataset[' global_sentiment_polarity'] = dataset['v_sentiment_Text']\n",
        "dataset[' abs_title_sentiment_polarity'] = dataset['v_sentiment_Title']\n",
        "dataset.drop(dataset.iloc[:, 0:4], inplace=True, axis=1)\n",
        "dataset.head()"
      ],
      "execution_count": 71,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_keywords</th>\n",
              "      <th>global_sentiment_polarity</th>\n",
              "      <th>abs_title_sentiment_polarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>13</td>\n",
              "      <td>0.075</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>1</th>\n",
              "      <td>14</td>\n",
              "      <td>0.039</td>\n",
              "      <td>0.184</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>2</th>\n",
              "      <td>12</td>\n",
              "      <td>0.062</td>\n",
              "      <td>0.000</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>3</th>\n",
              "      <td>15</td>\n",
              "      <td>0.073</td>\n",
              "      <td>0.242</td>\n",
              "    </tr>\n",
              "    <tr>\n",
              "      <th>4</th>\n",
              "      <td>15</td>\n",
              "      <td>0.031</td>\n",
              "      <td>0.143</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    num_keywords   global_sentiment_polarity   abs_title_sentiment_polarity\n",
              "0             13                       0.075                          0.000\n",
              "1             14                       0.039                          0.184\n",
              "2             12                       0.062                          0.000\n",
              "3             15                       0.073                          0.242\n",
              "4             15                       0.031                          0.143"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 71
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "5n9kfy265dht",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 80
        },
        "outputId": "1dbdc2c6-1ca6-4c04-ee9e-eaaa163a846c"
      },
      "source": [
        "# Normalize the numerical features\n",
        "from sklearn.preprocessing import MinMaxScaler\n",
        "scaler = MinMaxScaler()\n",
        "numerical = [' num_keywords',' global_sentiment_polarity',' abs_title_sentiment_polarity']\n",
        "dataset[numerical] = scaler.fit_transform(dataset[numerical])\n",
        "display(dataset.head(n = 1))"
      ],
      "execution_count": 72,
      "outputs": [
        {
          "output_type": "display_data",
          "data": {
            "text/html": [
              "<div>\n",
              "<style scoped>\n",
              "    .dataframe tbody tr th:only-of-type {\n",
              "        vertical-align: middle;\n",
              "    }\n",
              "\n",
              "    .dataframe tbody tr th {\n",
              "        vertical-align: top;\n",
              "    }\n",
              "\n",
              "    .dataframe thead th {\n",
              "        text-align: right;\n",
              "    }\n",
              "</style>\n",
              "<table border=\"1\" class=\"dataframe\">\n",
              "  <thead>\n",
              "    <tr style=\"text-align: right;\">\n",
              "      <th></th>\n",
              "      <th>num_keywords</th>\n",
              "      <th>global_sentiment_polarity</th>\n",
              "      <th>abs_title_sentiment_polarity</th>\n",
              "    </tr>\n",
              "  </thead>\n",
              "  <tbody>\n",
              "    <tr>\n",
              "      <th>0</th>\n",
              "      <td>0.166667</td>\n",
              "      <td>0.356688</td>\n",
              "      <td>0.0</td>\n",
              "    </tr>\n",
              "  </tbody>\n",
              "</table>\n",
              "</div>"
            ],
            "text/plain": [
              "    num_keywords   global_sentiment_polarity   abs_title_sentiment_polarity\n",
              "0       0.166667                    0.356688                            0.0"
            ]
          },
          "metadata": {
            "tags": []
          }
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "fswmQu0y2MZh",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        "final_prediction_ADA = clf_A.predict(dataset)\n",
        "final_prediction_LR = clf_B.predict(dataset.iloc[:, :2].values)\n",
        "final_prediction_RF = clf_C.predict(dataset)"
      ],
      "execution_count": 0,
      "outputs": []
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "csvbBUjA5osF",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "c9870511-f62a-4bce-ef85-6749a07ca4df"
      },
      "source": [
        "final_prediction_ADA"
      ],
      "execution_count": 83,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 1, 1, 1, 1, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 0, 1, 0, 0,\n",
              "       1, 0, 1, 1, 1, 0, 0, 0, 0, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 83
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "POGrUM_E5rGw",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "fd0e3d72-3c82-442d-e287-83d47c26058a"
      },
      "source": [
        "final_prediction_RF"
      ],
      "execution_count": 84,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([1, 0, 0, 1, 0, 0, 0, 1, 0, 0, 0, 0, 0, 0, 0, 1, 0, 1, 0, 0, 0, 0,\n",
              "       0, 1, 0, 1, 1, 1, 1, 0, 0, 1, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 84
        }
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "0M8fczVd7GUx",
        "colab_type": "code",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 51
        },
        "outputId": "d3c25a11-9dc6-448d-8343-e7ae85f3d364"
      },
      "source": [
        "final_prediction_LR"
      ],
      "execution_count": 85,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "array([0, 0, 0, 0, 0, 1, 1, 1, 0, 0, 0, 0, 0, 1, 0, 0, 1, 1, 0, 1, 0, 0,\n",
              "       1, 0, 1, 0, 0, 1, 0, 0, 0, 0, 1])"
            ]
          },
          "metadata": {
            "tags": []
          },
          "execution_count": 85
        }
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rWTHPE8B814p",
        "colab_type": "text"
      },
      "source": [
        "**Here '1' denotes that the number of shares will be greater than 1400(our initial assumption for being viral) and so the article is going to be viral according to our hypothesis.**"
      ]
    },
    {
      "cell_type": "code",
      "metadata": {
        "id": "nXM0_5Gp8Rbn",
        "colab_type": "code",
        "colab": {}
      },
      "source": [
        ""
      ],
      "execution_count": 0,
      "outputs": []
    }
  ]
}